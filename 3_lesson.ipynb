{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduzione\n",
    "\n",
    "In questo quaderno, andremo ad esaminare una pipeline base di Data Anlysis in Python dall'inizio alla fine per mostrarvi come si presenta un tipico flusso di lavoro."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dominio del problema\n",
    "\n",
    "Per gli scopi di questo esercizio, facciamo finta di lavorare per una startup che è stata appena finanziata per creare un'applicazione per smartphone che identifica automaticamente le specie di fiori dalle foto scattate con lo smartphone. \n",
    "\n",
    "Siamo stati incaricati dal responsabile della nostra azienda di creare un modello dimostrativo di machine learining che prende quattro misure dai fiori (lunghezza del sepalo, larghezza del sepalo, lunghezza del petalo e larghezza del petalo) e identifica la specie basandosi solo su queste misure.\n",
    "\n",
    "\n",
    "<img src=\"images/petal_sepal.jpg\" />\n",
    "\n",
    "Ci è stato dato un [dataset](https://github.com/rhiever/Data-Analysis-and-Machine-Learning-Projects/raw/master/example-data-science-notebook/iris-data.csv) dai nostri ricercatori per sviluppare la demo, che include solo misure per tre tipi di fiori *Iris*:\n",
    "\n",
    "\n",
    "### *Iris setosa*\n",
    "\n",
    "<img src=\"images/iris_setosa.jpg\" />\n",
    "\n",
    "### *Iris versicolor*\n",
    "<img src=\"images/iris_versicolor.jpg\" />\n",
    "\n",
    "### *Iris virginica*\n",
    "<img src=\"images/iris_virginica.jpg\" />\n",
    "\n",
    "Le quattro misurazioni che stiamo usando attualmente provengono da misurazioni manuali da parte dei ricercatori, ma in futuro saranno misurate automaticamente da un modello di elaborazione delle immagini."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Domande prima di iniziare\n",
    "\n",
    "Il primo passo di qualsiasi progetto di analisi dei dati è quello di definire la domanda o il problema che stiamo cercando di risolvere, e di definire una misura (o una serie di misure) per il nostro successo nel risolvere quel compito.\n",
    "\n",
    ">Hai specificato il tipo di domanda analitica sui dati?\n",
    "\n",
    "Stiamo cercando di classificare la specie (cioè la classe) del fiore in base a quattro misure che ci vengono fornite: lunghezza del sepalo, larghezza del sepalo, lunghezza del petalo e larghezza del petalo.\n",
    "\n",
    ">Hai definito la metrica di successo prima di iniziare?\n",
    "\n",
    "Poiché stiamo eseguendo la classificazione, possiamo usare [l'accuratezza](https://en.wikipedia.org/wiki/Accuracy_and_precision) - la frazione di fiori classificati correttamente - per quantificare quanto bene il nostro modello stia funzionando. Il responsabile dei dati della nostra azienda ci ha detto che dovremmo raggiungere almeno il 90% di accuratezza."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Controllare i dati\n",
    "\n",
    "Il passo successivo è guardare i dati con cui stiamo lavorando, è vitale individuare gli errori prima di investire troppo tempo nella nostra analisi.\n",
    "\n",
    "In generale, stiamo cercando di rispondere alle seguenti domande:\n",
    "\n",
    "* C'è qualcosa di sbagliato nei dati?\n",
    "* Ci sono delle stranezze nei dati?\n",
    "* Devo correggere o rimuovere qualche dato?\n",
    "\n",
    "Cominciamo a leggere i dati utilizzando un DataFrame di pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Siamo fortunati! I dati sembrano essere in un formato utilizzabile.\n",
    "\n",
    "La prima riga del file di dati definisce le intestazioni delle colonne, e le intestazioni sono abbastanza descrittive da permetterci di capire cosa rappresenta ogni colonna. Le intestazioni ci danno anche le unità in cui sono state registrate le misure, nel caso in cui avessimo bisogno di saperlo in un momento successivo del progetto.\n",
    "\n",
    "Ogni riga successiva alla prima rappresenta una voce per un fiore: quattro misure e una classe, che indica la specie del fiore.\n",
    "\n",
    "**Una delle prime cose che dovremmo cercare sono i dati mancanti.** Per fortuna, i ricercatori ci hanno già detto che mettono un 'NA' nel foglio di calcolo quando manca una misurazione.\n",
    "\n",
    "Possiamo dire a pandas di identificare automaticamente i valori mancanti se conosce il valore con cui sono stati marcati."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Ora pandas sa di trattare le righe con 'NA' come valori mancanti."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poi, è sempre una buona idea guardare la distribuzione dei nostri dati - specialmente i valori anomali.\n",
    "\n",
    "Cominciamo con la stampa di alcune statistiche riassuntive del dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possiamo ricavare diverse informazioni utili da questa tabella. Per esempio, vediamo che mancano cinque voci in `petal_width_cm`.\n",
    "\n",
    "Tabelle come questa sono raramente utili a meno che non sappiamo che i nostri dati dovrebbero rientrare in un particolare intervallo. Di solito è meglio visualizzare i dati in qualche modo. La visualizzazione fa risaltare immediatamente i valori anomali e gli errori, mentre potrebbero passare inosservati in una grande tabella di numeri.\n",
    "\n",
    "Dato che sappiamo che in questa sezione tracceremo dei grafici, impostiamo il notebook in modo da poter visualizzare i dati."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This line tells the notebook to show plots inside of the notebook\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ora creiamo una **matrice scatterplot**. Le matrici scatterplot tracciano la distribuzione di ogni colonna lungo la diagonale, e poi tracciano una matrice scatterplot per la combinazione di ogni variabile. Sono uno strumento efficiente per cercare errori nei nostri dati.\n",
    "\n",
    "Possiamo anche fare in modo che il pacchetto utilizzi colori diversi per ogni voce in base alla sua classe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dalla matrice dello scatterplot, possiamo già vedere alcuni problemi con il dataset:\n",
    "1. Ci sono cinque classi quando dovrebbero essercene solo tre, il che significa che ci sono stati alcuni errori di codifica.\n",
    "\n",
    "2. Ci sono alcuni chiari outlier nelle misurazioni che possono essere errati: una voce `sepal_width_cm` per `Iris-setosa` cade ben al di fuori del suo range normale, e diverse voci `sepal_length_cm` per `Iris-versicolor` sono vicine allo zero per qualche motivo.\n",
    "\n",
    "3. Abbiamo dovuto eliminare le righe con valori mancanti.\n",
    "\n",
    "In tutti questi casi, dobbiamo capire cosa fare con i dati errati. Il che ci porta al prossimo passo..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Ordinare i dati\n",
    "\n",
    "Ora che abbiamo identificato diversi errori nel set di dati, dobbiamo correggerli prima di procedere con l'analisi.\n",
    "\n",
    "Analizziamo i problemi uno per uno.\n",
    "\n",
    "> Ci sono cinque classi quando dovrebbero essercene solo tre, il che significa che ci sono stati alcuni errori di codifica.\n",
    "\n",
    "Dopo aver parlato con i ricercatori, sembra che uno di loro abbia dimenticato di aggiungere `Iris-` prima delle loro voci `Iris-versicolor`. L'altra classe estranea, `Iris-setossa`, era semplicemente un refuso che hanno dimenticato di correggere.\n",
    "\n",
    "Usiamo DataFrame per correggere gli errori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_data.loc[__________________] = 'Iris-versicolor'\n",
    "iris_data.loc[__________________] = 'Iris-setosa'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Molto meglio! Ora abbiamo solo tre tipi di classi.\n",
    "\n",
    ">Ci sono alcuni chiari outlier nelle misurazioni che possono essere errati: una voce `sepal_width_cm` per `Iris-setosa` cade ben al di fuori del suo range normale, e diverse voci `sepal_length_cm` per `Iris-versicolor` sono vicine allo zero per qualche motivo.\n",
    "\n",
    "Correggere i valori anomali può essere un problema complicato. Raramente è chiaro se l'outlier è stato causato da un errore di misurazione, dalla registrazione dei dati in unità improprie, o se l'outlier è una vera anomalia. Per questo motivo, dovremmo essere prudenti quando lavoriamo con i valori anomali: se decidiamo di escludere dei dati, dobbiamo assicurarci di documentare quali dati abbiamo escluso e fornire una solida motivazione per l'esclusione di quei dati.\n",
    "\n",
    "Nel caso della voce anomala per `Iris-setosa`, diciamo che i nostri ricercatori sanno che è impossibile che `Iris-setosa` abbia una larghezza del sepalo inferiore a 2,5 cm. È chiaro che questa voce è stata fatta per errore, ed è meglio eliminare la voce piuttosto che spendere ore per scoprire cosa è successo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Questa linea di codice elimina tutte le righe 'Iris-setosa' con una lunghezza del sepalo minore di 2.5 cm\n",
    "iris_data = iris_data.loc[(iris_data['class'] != '________') | (iris_data['sepal_width_cm'] >= ________)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_data.loc[iris_data['class'] == 'Iris-setosa', 'sepal_width_cm'].hist()\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eccellente! Ora tutte le nostre file di \"Iris-setosa\" hanno una larghezza del sepalo maggiore di 2,5.\n",
    "\n",
    "Il prossimo problema di dati da affrontare sono le diverse lunghezze quasi nulle dei sepali per le righe di `Iris-versicolor`. Diamo un'occhiata a queste righe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizziamo le righe 'Iris-versicolor' con una lunghezza del sepalo minore di 1.0 cm\n",
    "iris_data.loc[() & ()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tutte queste voci di `sepal_length_cm` vicine allo zero sembrano essere sbagliate di due ordini di grandezza, come se fossero state registrate in metri invece che in centimetri.\n",
    "\n",
    "Dopo una breve corrispondenza con i ricercatori, scopriamo che uno di loro ha dimenticato di convertire queste misure in centimetri."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_data.loc[() & (), ''] *= "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_data.loc[iris_data['class'] == 'Iris-versicolor', 'sepal_length_cm'].hist()\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diamo un'occhiata alle righe con valori mancanti:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_data.loc[(iris_data['sepal_length_cm'].isnull()) |\n",
    "              (iris_data['sepal_width_cm'].isnull()) |\n",
    "              (iris_data['petal_length_cm'].isnull()) |\n",
    "              (iris_data['petal_width_cm'].isnull())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Non è l'ideale dover eliminare quelle righe, specialmente considerando che sono tutte voci `Iris-setosa`. Poiché sembra che i dati mancanti siano sistematici - tutti i valori mancanti sono nella stessa colonna per lo stesso tipo *Iris* - questo errore potrebbe potenzialmente distorcere la nostra analisi.\n",
    "\n",
    "Un modo per trattare i dati mancanti è l'imputazione media: Se sappiamo che i valori di una misura rientrano in un certo intervallo, possiamo riempire i valori vuoti con la media di quella misura.\n",
    "\n",
    "Vediamo se possiamo farlo qui."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_data.loc[iris_data['class'] == 'Iris-setosa', 'petal_width_cm'].hist()\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La maggior parte delle larghezze dei petali di `Iris-setosa` rientrano nell'intervallo 0,2-0,3, quindi riempiamo queste voci con la larghezza media misurata dei petali."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calcoliamo la media\n",
    "_______ = _______.loc[___].__()\n",
    "\n",
    "iris_data.loc[(______ == '____') & (_____),\n",
    "              '______'] = ________\n",
    "\n",
    "iris_data.loc[(iris_data['class'] == '_______') &\n",
    "              (iris_data['petal_width_cm'] == ________)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verifichiamo che non ci sono più valori nulli!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ottimo! Ora abbiamo recuperato quelle righe e non abbiamo più dati mancanti nel nostro set di dati.\n",
    "\n",
    "Dopo tutto questo duro lavoro, non vogliamo ripetere questo processo ogni volta che lavoriamo con il dataset. Salviamo il file riordinato *come un file separato* e lavoriamo direttamente con quel dataset d'ora in poi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diamo un'occhiata alla matrice dello scatterplot ora che abbiamo messo in ordine i dati."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.pairplot(iris_data_clean, hue='class')\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Classification\n",
    "\n",
    "Sicuri che i nostri dati sono ora il più puliti possibile - e dotati di una conoscenza sommaria delle distribuzioni e delle relazioni nel nostro set di dati - è il momento di fare il prossimo grande passo nella nostra analisi: Dividere i dati in insiemi di allenamento e di test.\n",
    "\n",
    "Un **training set** è un sottoinsieme casuale di dati che usiamo per addestrare i nostri modelli.\n",
    "\n",
    "Un **testing set** è un sottoinsieme casuale di dati (mutuamente esclusivo del set di allenamento) che usiamo per validare i nostri modelli.\n",
    "\n",
    "Specialmente in insiemi di dati sparsi come i nostri, è facile per i modelli facciaiano un **overfit** dei dati: Il modello imparerà il set di allenamento così bene che non sarà in grado di gestire la maggior parte dei casi in cui gli venga presentato un dato mai visto prima. Questo è il motivo per cui è importante per noi costruire il modello con il set di allenamento, ma valutarlo con il set di test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_data_clean = pd.read_csv('datasets/iris-data-clean.csv')\n",
    "\n",
    "all_inputs = \n",
    "all_labels = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ora i nostri dati sono pronti per essere divisi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I classificatori ad albero di decisione sono incredibilmente semplici in teoria. Nella loro forma più semplice, i classificatori ad albero di decisione pongono una serie di domande Sì/No sui dati - ogni volta sempre più vicini a scoprire la classe di ogni voce - finché non classificano perfettamente il set di dati o semplicemente non riescono a differenziare più una serie di voci.\n",
    "\n",
    "Esempio:\n",
    "\n",
    "<img src=\"images/iris_dtc.png\" />\n",
    "\n",
    "Notate come il classificatore pone domande Sì/No sui dati - se una certa caratteristica è <= 1,75, per esempio - In questo modo può differenziare i record.\n",
    "\n",
    "La parte bella dei classificatori ad albero di decisione è che sono **scale-invariant**, cioè, la scala delle caratteristiche non influenza le loro prestazioni, a differenza di molti modelli di Machine Learning. In altre parole, non importa se le nostre caratteristiche vanno da 0 a 1 o da 0 a 1.000; i classificatori ad albero di decisione lavoreranno allo stesso modo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Creare il classificatore\n",
    "___________ = DecisionTreeClassifier()\n",
    "\n",
    "# Effettuare il train \n",
    "\n",
    "\n",
    "# Testare i risultati\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il nostro modello raggiunge il 97% di precisione di classificazione senza molto sforzo.\n",
    "\n",
    "Tuttavia, c'è una fregatura: A seconda di come il nostro set di allenamento e di test è stato campionato, il nostro modello può raggiungere ovunque dall'80% al 100% di precisione:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_accuracies = []\n",
    "    \n",
    "plt.hist(model_accuracies)\n",
    ";"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
